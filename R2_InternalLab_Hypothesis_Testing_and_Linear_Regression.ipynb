{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IEJOH3pMy_EG"
   },
   "source": [
    "\n",
    "\n",
    "## Lab 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yRG2Rb6By_EK"
   },
   "source": [
    "Welcome to the second lab of the AIML!\n",
    "In addition to implementing code, there will be questions that you must answer which relate to the lab and your implementation. Each question you will answer is preceded by a **'Question X'** header. Carefully read each question and provide you answer or code in the following textboxes with **'Answer:'** header. Your lab submission will be evaluated based on your answers to each of the questions and the implementation you provide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wv9-kA4vy_EN"
   },
   "source": [
    "# Every question is of 1 mark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c7F5I7f9y_EQ"
   },
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DbanWtFwzc-A"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s3TbncQ0y_ES"
   },
   "source": [
    "This module covers,\n",
    "\n",
    "1) One sample and Two sample t-tests\n",
    "\n",
    "2) ANOVA\n",
    "\n",
    "3) Type I and Type II errors\n",
    "\n",
    "4) Probabilty Distributions\n",
    "\n",
    "5) Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i8UE0UE6y_EV"
   },
   "source": [
    "## Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kImA4Gk-y_EW"
   },
   "source": [
    "The purpose of the test is to tell if there is any significant difference between two data sets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yItvHo3By_EZ"
   },
   "source": [
    "## Question 1 \n",
    "\n",
    "*A student is trying to decide between two GPUs. He want to use the GPU for his research to run Deep learning algorithms, so the only thing he is concerned with is speed.*\n",
    "\n",
    "*He picks a Deep Learning algorithm on a large data set and runs it on both GPUs 15 times, timing each run in hours. Results are given in the below lists GPU1 and GPU2.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nnQ2Ftdgy_Ea"
   },
   "source": [
    "Hint: You can import ttest function from scipy to perform t tests "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JbQ05nufy_Ec"
   },
   "source": [
    "Given,\n",
    "\n",
    "Null Hypothesis : There is no significant difference between data sets\n",
    "\n",
    "Alternate Hypothesis : There is a significant difference\n",
    "\n",
    "*Do two-sample testing and check whether to reject Null Hypothesis or not.*\n",
    "\n",
    "#### Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zg9r4020y_Ee"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import ttest_1samp, ttest_ind, wilcoxon\n",
    "GPU1 = pd.DataFrame([11,9,10,11,10,12,9,11,12,9,11,12,9,10,9])\n",
    "GPU2 = pd.DataFrame([11,13,10,13,12,9,11,12,12,11,12,12,10,11,13])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VqYtQt37y_El"
   },
   "source": [
    "[## Question 2 \n",
    "](https://)\n",
    "He is trying a third GPU which is GPU3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rejecting Null Hypothesis since p_value is less than 0.05 \n",
      "Accepting Alternate Hypothesis : There is a significant difference\n"
     ]
    }
   ],
   "source": [
    "# GPU1, GPU2 are both independent, as out come of GPU1 is not impacting GPU2\n",
    "# Since p_value < 0.05 (taking 95% confidence level). Rejecting null hypothesis so. There is signficant difference.\n",
    "t_statistic, p_value = ttest_ind(GPU1, GPU2)\n",
    "#print(\"t_statistic\",t_statistic)\n",
    "#print(\"p_value\",p_value)\n",
    "if(p_value<0.05):\n",
    "    print(\"Rejecting Null Hypothesis since p_value is less than 0.05 \")\n",
    "    print(\"Accepting Alternate Hypothesis : There is a significant difference\")\n",
    "else:\n",
    "    print(\"Accepting Null Hypothesis since p_value is greater than 0.05 \")\n",
    "    print(\"Accepted Null Hypothesis : There is no significant difference between data sets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JM3dI6Kpy_Eo"
   },
   "outputs": [],
   "source": [
    "GPU3 = pd.DataFrame([9,10,9,11,10,13,12,9,12,12,13,12,13,10,11])\n",
    "\n",
    "#Assumption: Both the datasets (GPU1 & GPU 3) are random, independent, parametric & normally distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xccR5TB4y_Ev"
   },
   "source": [
    "*Do two-sample testing and check whether there is significant differene between speeds of two GPUs GPU1 and GPU3.*\n",
    "\n",
    "#### Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uQUx17MFy_Ex"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accepting Null Hypothesis since p_value is greater than 0.05 \n",
      "Accepted Null Hypothesis : There is no significant difference between data sets\n"
     ]
    }
   ],
   "source": [
    "t_statistic1, p_value1 = ttest_ind(GPU1, GPU3)\n",
    "#print(\"t_statistic1\",t_statistic1)\n",
    "#print(\"p_value1\",p_value1)\n",
    "if(p_value1<0.05):\n",
    "    print(\"Rejecting Null Hypothesis since p_value is less than 0.05 \")\n",
    "    print(\"Accepting Alternate Hypothesis : There is a significant difference\")\n",
    "else:\n",
    "    print(\"Accepting Null Hypothesis since p_value is greater than 0.05 \")\n",
    "    print(\"Accepted Null Hypothesis : There is no significant difference between data sets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1ntmaD07y_E2"
   },
   "source": [
    "### ANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G0pj7K4jy_E4"
   },
   "source": [
    "## Question 3 \n",
    "\n",
    "If you need to compare more than two data sets at a time, an ANOVA is your best bet. \n",
    "\n",
    "*The results from three experiments with overlapping 95% confidence intervals are given below, and we want to confirm that the results for all three experiments are not significantly different.*\n",
    "\n",
    "#Assumption: All the 3 datasets (e1,e2 & e3) are random, independent, parametric & normally distributed\n",
    "But before conducting ANOVA, test equality of variances (using Levene's test) is satisfied or not. If not, then mention that we cannot depend on the result of ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AKzdGmBWy_E7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.59544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.41973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0\n",
       "0  1.59544\n",
       "1  1.41973\n",
       "2  0.00000\n",
       "3  0.00000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import levene, shapiro, f_oneway\n",
    "e1 = pd.DataFrame([1.595440,1.419730,0.000000,0.000000])\n",
    "e2 = pd.DataFrame([1.433800,2.079700,0.892139,2.384740])\n",
    "e3 = pd.DataFrame([0.036930,0.938018,0.995956,1.006970])\n",
    "e1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iZ5OpNTZy_FH"
   },
   "source": [
    "Hint - You can use stats.levene function and stats.f_oneway function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LS7fFigZy_FM"
   },
   "source": [
    "#### Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JeTpweFsy_FP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variances are equal\n"
     ]
    }
   ],
   "source": [
    "# Levene's Test\n",
    "\n",
    "\n",
    "result = levene(e1[0],e2[0],e3[0])\n",
    "\n",
    "\n",
    "if(result.pvalue>0.05):\n",
    "    print(\"variances are equal\")\n",
    "else:\n",
    "    print(\"variances are not equal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-way ANOVA\n",
      "=============\n",
      "F value: 2.51357622845924\n",
      "P value: 0.13574644501798466 \n",
      "\n",
      "results for all three experiments are not significantly different\n"
     ]
    }
   ],
   "source": [
    "f, p = f_oneway(e1[0],e2[0],e3[0])\n",
    " \n",
    "print ('One-way ANOVA')\n",
    "print ('=============')\n",
    " \n",
    "print ('F value:', f)\n",
    "print ('P value:', p, '\\n')\n",
    "\n",
    "# p-value > 0.05 hence results for all three experiments are not significantly different\n",
    "if(p>0.05):\n",
    "    print(\"results for all three experiments are not significantly different\")\n",
    "else:\n",
    "    print(\"results for all three experiments are significantly different\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-QkO7Zdky_FY"
   },
   "source": [
    "## Question 4 \n",
    "\n",
    "*In one or two sentences explain about **TypeI** and **TypeII** errors.*\n",
    "\n",
    "#### Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Type1 error occurs when we reject null hypothesis when we should have retained it. \n",
    "#Examples of type I errors include a test that shows a patient to have a disease when in fact the patient does not have the disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7GMrA5hiy_Fc"
   },
   "outputs": [],
   "source": [
    "#Type2 error occurs when we fail to reject the null hypothesis.\n",
    "#Examples of type II errors would be a blood test failing to detect the disease it was designed to detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6x2cZFpyy_Fi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HjY6P__6y_Fm"
   },
   "source": [
    "# Question 5\n",
    "You are a manager of a chinese restaurant. You want to determine whether the waiting time to place an order has changed in the past month from its previous population mean value of 4.5 minutes. \n",
    "State the null and alternative hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lV5GQ6T8y_Fp"
   },
   "outputs": [],
   "source": [
    "# Null Hypothesis H0: waiting time to place an order in past month from its previous population mean is 4.5 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rKmKCB_Fy_Fu"
   },
   "outputs": [],
   "source": [
    "# Alternative Hypothesis H1: waiting time to place an order in past month from its previous population mean is 4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hh8GpzDny_Fy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gflwdh5qy_F4"
   },
   "source": [
    "# Question 6 \n",
    "Get the binomial distribution with n = 10, p = .7 and k = [0, 1, 2, 3, 4, 5, 6, 7]\n",
    "\n",
    "Hint - Use stats.binom.pmf() function for this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u43Z8ZM-y_F5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.90490000e-06, 1.37781000e-04, 1.44670050e-03, 9.00169200e-03,\n",
       "       3.67569090e-02, 1.02919345e-01, 2.00120949e-01, 2.66827932e-01])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import binom\n",
    "k = [0, 1, 2, 3, 4, 5, 6, 7]\n",
    "data_binom = binom.pmf(k, 10, 0.7)\n",
    "data_binom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D5whZ6A5y_F9"
   },
   "source": [
    "# Question 7 \n",
    "Plot the distribution created in the above question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "emY4gr4Jy_F_"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vamshidhar\\Anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Text(0,0.5,'Frequency'), Text(0.5,0,'Binomial')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "ax = sns.distplot(data_binom,\n",
    "                  kde=False,\n",
    "                  color='skyblue',\n",
    "                  hist_kws={\"linewidth\": 15,'alpha':1})\n",
    "ax.set(xlabel='Binomial', ylabel='Frequency')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wMKyZctHy_GE"
   },
   "source": [
    "# Linear Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LDJS2-Pgy_GH"
   },
   "source": [
    "# Simple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1aXhBleCy_GM"
   },
   "source": [
    "Here we will try to see that if we can make a regression model to predict one column of a dataset by the use of other coloumn.\n",
    "\n",
    "## Dataset\n",
    "\n",
    "Population of U.S. Cities\n",
    "\n",
    "### Description\n",
    "The bigcity data frame has 49 rows and 2 columns.\n",
    "\n",
    "The measurements are the population (in 1000's) of 49 U.S. cities in 1920 and 1930. The 49 cities are a random sample taken from the 196 largest cities in 1920.\n",
    "\n",
    "### Format\n",
    "This data frame contains the following columns:\n",
    "\n",
    "`u`\n",
    "The 1920 population.\n",
    "\n",
    "`x`\n",
    "The 1930 population.\n",
    "\n",
    "There is one unnamed column also in this dataset. Please remove and ignore that coloumn.\n",
    "\n",
    "Source\n",
    "\n",
    "The data were obtained from\n",
    "\n",
    "Cochran, W.G. (1977) Sampling Techniques. Third edition. John Wiley\n",
    "\n",
    "References\n",
    "\n",
    "Davison, A.C. and Hinkley, D.V. (1997) Bootstrap Methods and Their Application. Cambridge University Press."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jR6a2l7my_GO"
   },
   "source": [
    "# Question 8 \n",
    "Read the dataset given in file named 'bigcity.csv'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2syrwIZey_GQ"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>u</th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>138</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>93</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>179</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>48</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>37</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>29</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>38</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>46</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>71</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>25</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>298</td>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>74</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>50</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>76</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>381</td>\n",
       "      <td>464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>387</td>\n",
       "      <td>459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>78</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>60</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>507</td>\n",
       "      <td>634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>50</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>77</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>64</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>40</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>136</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>243</td>\n",
       "      <td>291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>256</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>94</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>36</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>45</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>120</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36</td>\n",
       "      <td>172</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37</td>\n",
       "      <td>66</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38</td>\n",
       "      <td>46</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39</td>\n",
       "      <td>121</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40</td>\n",
       "      <td>44</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>41</td>\n",
       "      <td>64</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>42</td>\n",
       "      <td>56</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>43</td>\n",
       "      <td>40</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>44</td>\n",
       "      <td>116</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>45</td>\n",
       "      <td>87</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>46</td>\n",
       "      <td>43</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>47</td>\n",
       "      <td>43</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>48</td>\n",
       "      <td>161</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49</td>\n",
       "      <td>36</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0    u    x\n",
       "0            1  138  143\n",
       "1            2   93  104\n",
       "2            3   61   69\n",
       "3            4  179  260\n",
       "4            5   48   75\n",
       "5            6   37   63\n",
       "6            7   29   50\n",
       "7            8   23   48\n",
       "8            9   30  111\n",
       "9           10    2   50\n",
       "10          11   38   52\n",
       "11          12   46   53\n",
       "12          13   71   79\n",
       "13          14   25   57\n",
       "14          15  298  317\n",
       "15          16   74   93\n",
       "16          17   50   58\n",
       "17          18   76   80\n",
       "18          19  381  464\n",
       "19          20  387  459\n",
       "20          21   78  106\n",
       "21          22   60   57\n",
       "22          23  507  634\n",
       "23          24   50   64\n",
       "24          25   77   89\n",
       "25          26   64   77\n",
       "26          27   40   60\n",
       "27          28  136  139\n",
       "28          29  243  291\n",
       "29          30  256  288\n",
       "30          31   94   85\n",
       "31          32   36   46\n",
       "32          33   45   53\n",
       "33          34   67   67\n",
       "34          35  120  115\n",
       "35          36  172  183\n",
       "36          37   66   86\n",
       "37          38   46   65\n",
       "38          39  121  113\n",
       "39          40   44   58\n",
       "40          41   64   63\n",
       "41          42   56  142\n",
       "42          43   40   64\n",
       "43          44  116  130\n",
       "44          45   87  105\n",
       "45          46   43   61\n",
       "46          47   43   50\n",
       "47          48  161  232\n",
       "48          49   36   54"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(pd.read_csv(\"bigcity.csv\"))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z2xteyYby_GT"
   },
   "source": [
    "# Question 9 - Transform the dataset \n",
    "Find the number of rows in given dataset and separate the input(u column)  and target variables(x column) into X and Y.\n",
    "\n",
    "Remove the unnamed coloumn.\n",
    "\n",
    "Hint: You can shape function to get the size of the dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7KJUYwDMy_GX"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u</th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>138</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>179</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>37</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>29</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>23</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>30</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>38</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>46</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>71</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>25</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>298</td>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>74</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>50</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>76</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>381</td>\n",
       "      <td>464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>387</td>\n",
       "      <td>459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>78</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>60</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>507</td>\n",
       "      <td>634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>50</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>77</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>64</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>40</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>136</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>243</td>\n",
       "      <td>291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>256</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>94</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>36</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>45</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>120</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>172</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>66</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>46</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>121</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>44</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>64</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>56</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>40</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>116</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>87</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>43</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>43</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>161</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>36</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      u    x\n",
       "0   138  143\n",
       "1    93  104\n",
       "2    61   69\n",
       "3   179  260\n",
       "4    48   75\n",
       "5    37   63\n",
       "6    29   50\n",
       "7    23   48\n",
       "8    30  111\n",
       "9     2   50\n",
       "10   38   52\n",
       "11   46   53\n",
       "12   71   79\n",
       "13   25   57\n",
       "14  298  317\n",
       "15   74   93\n",
       "16   50   58\n",
       "17   76   80\n",
       "18  381  464\n",
       "19  387  459\n",
       "20   78  106\n",
       "21   60   57\n",
       "22  507  634\n",
       "23   50   64\n",
       "24   77   89\n",
       "25   64   77\n",
       "26   40   60\n",
       "27  136  139\n",
       "28  243  291\n",
       "29  256  288\n",
       "30   94   85\n",
       "31   36   46\n",
       "32   45   53\n",
       "33   67   67\n",
       "34  120  115\n",
       "35  172  183\n",
       "36   66   86\n",
       "37   46   65\n",
       "38  121  113\n",
       "39   44   58\n",
       "40   64   63\n",
       "41   56  142\n",
       "42   40   64\n",
       "43  116  130\n",
       "44   87  105\n",
       "45   43   61\n",
       "46   43   50\n",
       "47  161  232\n",
       "48   36   54"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(df.columns[df.columns.str.contains(\"Unnamed\", case=False)], axis=1, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      u\n",
       "0   138\n",
       "1    93\n",
       "2    61\n",
       "3   179\n",
       "4    48\n",
       "5    37\n",
       "6    29\n",
       "7    23\n",
       "8    30\n",
       "9     2\n",
       "10   38\n",
       "11   46\n",
       "12   71\n",
       "13   25\n",
       "14  298\n",
       "15   74\n",
       "16   50\n",
       "17   76\n",
       "18  381\n",
       "19  387\n",
       "20   78\n",
       "21   60\n",
       "22  507\n",
       "23   50\n",
       "24   77\n",
       "25   64\n",
       "26   40\n",
       "27  136\n",
       "28  243\n",
       "29  256\n",
       "30   94\n",
       "31   36\n",
       "32   45\n",
       "33   67\n",
       "34  120\n",
       "35  172\n",
       "36   66\n",
       "37   46\n",
       "38  121\n",
       "39   44\n",
       "40   64\n",
       "41   56\n",
       "42   40\n",
       "43  116\n",
       "44   87\n",
       "45   43\n",
       "46   43\n",
       "47  161\n",
       "48   36"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Data Set\n",
    "X = df.iloc[:,1:2]\n",
    "Y = df.iloc[:,:1]\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TyuhJDK5y_Gc"
   },
   "source": [
    "## Question 10 - Check the dataset for any missing values and also print out the correlation matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hpzkRe81y_Gd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u</th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        u      x\n",
       "0   False  False\n",
       "1   False  False\n",
       "2   False  False\n",
       "3   False  False\n",
       "4   False  False\n",
       "5   False  False\n",
       "6   False  False\n",
       "7   False  False\n",
       "8   False  False\n",
       "9   False  False\n",
       "10  False  False\n",
       "11  False  False\n",
       "12  False  False\n",
       "13  False  False\n",
       "14  False  False\n",
       "15  False  False\n",
       "16  False  False\n",
       "17  False  False\n",
       "18  False  False\n",
       "19  False  False\n",
       "20  False  False\n",
       "21  False  False\n",
       "22  False  False\n",
       "23  False  False\n",
       "24  False  False\n",
       "25  False  False\n",
       "26  False  False\n",
       "27  False  False\n",
       "28  False  False\n",
       "29  False  False\n",
       "30  False  False\n",
       "31  False  False\n",
       "32  False  False\n",
       "33  False  False\n",
       "34  False  False\n",
       "35  False  False\n",
       "36  False  False\n",
       "37  False  False\n",
       "38  False  False\n",
       "39  False  False\n",
       "40  False  False\n",
       "41  False  False\n",
       "42  False  False\n",
       "43  False  False\n",
       "44  False  False\n",
       "45  False  False\n",
       "46  False  False\n",
       "47  False  False\n",
       "48  False  False"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fMy6zL1Ky_Gh"
   },
   "source": [
    "You can use .isna() and .corr() functions to check NA's and correlation in the dataframe respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hpJlVUupy_Gi"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u</th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>u</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.981742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x</th>\n",
       "      <td>0.981742</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          u         x\n",
       "u  1.000000  0.981742\n",
       "x  0.981742  1.000000"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tqMEX2t-y_Gn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O05wXnYhy_Gs"
   },
   "source": [
    "### The high correlation betwwen u and x indicates that the variable u is a good predictor of variable x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NWu2j-iFy_Gt"
   },
   "source": [
    "# Question 11 - Split data into train, test sets \n",
    "Divide the data into training and test sets with 80-20 split using scikit-learn. Print the shapes of training and test feature sets.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2xGeBU-Fy_Gv"
   },
   "source": [
    "Check: train_test_split function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uKcfywXEy_Gw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      x\n",
      "11   53\n",
      "31   46\n",
      "33   67\n",
      "27  139\n",
      "48   54\n",
      "2    69\n",
      "46   50\n",
      "18  464\n",
      "15   93\n",
      "28  291\n",
      "22  634\n",
      "16   58\n",
      "41  142\n",
      "20  106\n",
      "42   64\n",
      "8   111\n",
      "13   57\n",
      "25   77\n",
      "5    63\n",
      "17   80\n",
      "35  183\n",
      "14  317\n",
      "38  113\n",
      "1   104\n",
      "12   79\n",
      "43  130\n",
      "24   89\n",
      "6    50\n",
      "23   64\n",
      "36   86\n",
      "21   57\n",
      "19  459\n",
      "9    50\n",
      "39   58\n",
      "45   61\n",
      "3   260\n",
      "0   143\n",
      "47  232\n",
      "44  105\n",
      "      x\n",
      "29  288\n",
      "4    75\n",
      "26   60\n",
      "30   85\n",
      "32   53\n",
      "37   65\n",
      "34  115\n",
      "40   63\n",
      "7    48\n",
      "10   52\n",
      "      u\n",
      "11   46\n",
      "31   36\n",
      "33   67\n",
      "27  136\n",
      "48   36\n",
      "2    61\n",
      "46   43\n",
      "18  381\n",
      "15   74\n",
      "28  243\n",
      "22  507\n",
      "16   50\n",
      "41   56\n",
      "20   78\n",
      "42   40\n",
      "8    30\n",
      "13   25\n",
      "25   64\n",
      "5    37\n",
      "17   76\n",
      "35  172\n",
      "14  298\n",
      "38  121\n",
      "1    93\n",
      "12   71\n",
      "43  116\n",
      "24   77\n",
      "6    29\n",
      "23   50\n",
      "36   66\n",
      "21   60\n",
      "19  387\n",
      "9     2\n",
      "39   44\n",
      "45   43\n",
      "3   179\n",
      "0   138\n",
      "47  161\n",
      "44   87\n",
      "      u\n",
      "29  256\n",
      "4    48\n",
      "26   40\n",
      "30   94\n",
      "32   45\n",
      "37   46\n",
      "34  120\n",
      "40   64\n",
      "7    23\n",
      "10   38\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(X, Y, test_size = 0.2, random_state = 0)\n",
    "print(xTrain)\n",
    "print(xTest)\n",
    "print(yTrain)\n",
    "print(yTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tejO-bEhy_Gz"
   },
   "source": [
    "# Question 12 - Find coefficients & intercept\n",
    "Estimate the coefficients b0 and b1 using scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hvex1b0ly_G2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load function from sklearn\n",
    "from sklearn import linear_model\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(Y, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZPcpfUIyy_G8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1577337039322437"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = regr.coef_[0][0]\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p0TWJsooy_HA"
   },
   "source": [
    "Check: coef_ and intercept_ functions can help you get coefficients & intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.383956333192671"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = regr.intercept_[0]\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LhtToZvAy_HB"
   },
   "source": [
    "# Question 13 - Linear Relationship between feature and target \n",
    "Plot the line with b1 and b0 as slope and y-intercept.\n",
    "\n",
    "Hint - y = mx + c, plot y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-9CG10Evy_HD"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x236a3bf9c88>]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(X,m*X+c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eZxObh5Wy_HG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ji-pKQMty_HJ"
   },
   "source": [
    "# Question 14 - Evaluation of model with scikit-learn \n",
    "Validate the model with Root Mean Squares error and R^2 score using scikit-learn. RMSE and R2 for test data and prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CwT09ICUy_HK"
   },
   "source": [
    "Hint: You can import mean_squared_error function & r2 (R square) from sklearn.metrics. Performing root operation over mean square error over mean square error gives you root mean square error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OCJnyT_py_HL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.73537644778138\n"
     ]
    }
   ],
   "source": [
    "#y_pred = lm.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "y_pred = regr.predict(xTest)\n",
    "mse = mean_squared_error(yTest, y_pred)\n",
    "\n",
    "rmse = sqrt(mse)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zFiUy7z2y_HT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1YTkh9Fgy_HX"
   },
   "source": [
    "## Question 15 - Calculate the accuracy of the model for both training and test data set "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4ZUDAcG-y_HX"
   },
   "source": [
    "### Hint: .score() function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HVOq2k33y_HY"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.10448820881899401"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Data Set\n",
    "regr.score(y_pred, yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xEUJL7-Qy_Hc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.963817258548811"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Data Set\n",
    "regr.score(Y, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YRGRNbqay_Hi"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "InternalLab_Residency2_Hypothesis_Testing_and_Linear_Regression-updated.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
